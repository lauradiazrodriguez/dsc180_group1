{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7aade4-ddc1-4dfa-ba91-53c2b8b1d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from typing import Tuple\n",
    "\n",
    "# Causal-Learn Imports\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.utils.GraphUtils import GraphUtils\n",
    "from causallearn.graph.SHD import SHD \n",
    "from causallearn.graph.GraphNode import GraphNode\n",
    "from causallearn.graph.GeneralGraph import GeneralGraph\n",
    "\n",
    "def plot_comparison_graphs(true_graph_obj, learned_graph_obj, labels, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    helper func to plot the ground truth and learned graphs side-by-side\n",
    "    \n",
    "    Args:\n",
    "        true_graph_obj (GeneralGraph): The graph object for the ground truth.\n",
    "        learned_graph_obj (GeneralGraph): The graph object returned by the PC algorithm.\n",
    "        labels (list): A list of variable names.\n",
    "        title_prefix (str): A title for the entire plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1-row, 2-column plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    fig.suptitle(title_prefix, fontsize=24, y=1.05) # Add a main title\n",
    "    \n",
    "    \n",
    "    # pydot object from the graph\n",
    "    pyd_true = GraphUtils.to_pydot(true_graph_obj, labels=labels)\n",
    "    \n",
    "    # convert pydot to PNG image\n",
    "    tmp_png_true = pyd_true.create_png(f=\"png\")\n",
    "    fp_true = io.BytesIO(tmp_png_true)\n",
    "    img_true = mpimg.imread(fp_true, format='png')\n",
    "    \n",
    "    # display image on first plot\n",
    "    axes[0].imshow(img_true)\n",
    "    axes[0].set_title(\"Ground Truth DAG\", fontsize=20)\n",
    "    axes[0].axis('off') # Hide axes\n",
    "    \n",
    "    \n",
    "    # create pydot object from learned graph\n",
    "    pyd_learned = GraphUtils.to_pydot(learned_graph_obj, labels=labels)\n",
    "    \n",
    "    # convert pydot to PNG image\n",
    "    tmp_png_learned = pyd_learned.create_png(f=\"png\")\n",
    "    fp_learned = io.BytesIO(tmp_png_learned)\n",
    "    img_learned = mpimg.imread(fp_learned, format='png')\n",
    "    \n",
    "    # display image on second plot\n",
    "    axes[1].imshow(img_learned)\n",
    "    axes[1].set_title(\"Learned Graph (CPDAG) from PC\", fontsize=20)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_and_print_metrics(true_graph_obj: GeneralGraph, learned_graph_obj: GeneralGraph) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Calculates and prints Structural Precision, Recall, and F1-score \n",
    "    (based on edge adjacency only) by manually comparing the adjacency matrices.\n",
    "    \n",
    "    The comparison is done on UNDIRECTED edges (existence of an edge, \n",
    "    A-B vs. A->B or B->A).\n",
    "    \n",
    "    Args:\n",
    "        true_graph_obj (GeneralGraph): The ground truth graph object.\n",
    "        learned_graph_obj (GeneralGraph): The graph object learned by the PC algorithm.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[float, float, float]: (Precision, Recall, F1-score)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Extract Adjacency Matrices using the public 'graph' attribute.\n",
    "    # The 'graph' attribute is listed in dir(true_graph_obj) and typically holds \n",
    "    # the underlying NumPy matrix for the GeneralGraph object in this library.\n",
    "    \n",
    "    true_adj = true_graph_obj.graph\n",
    "    learned_adj = learned_graph_obj.graph\n",
    "    \n",
    "    # 2. Symmetrize Matrices for Adjacency-Only Comparison\n",
    "    \n",
    "    def symmetrize_matrix(A):\n",
    "        \"\"\"Returns a binary matrix where A[i,j]=1 if A[i,j] or A[j,i] is non-zero.\"\"\"\n",
    "        # Convert non-zero entries (1, 2, 3, 4, etc. for different edge types) to 1 (edge exists)\n",
    "        A_binary = (A != 0).astype(int)\n",
    "        # Symmetrize: an edge exists if A->B OR B->A exists.\n",
    "        return ((A_binary + A_binary.T) != 0).astype(int)\n",
    "\n",
    "    True_Edges_Sym = symmetrize_matrix(true_adj)\n",
    "    Learned_Edges_Sym = symmetrize_matrix(learned_adj)\n",
    "    \n",
    "    # 3. Calculate Confusion Matrix components (TP, FP, FN)\n",
    "    \n",
    "    # Mask for unique edges (upper triangle, excluding diagonal)\n",
    "    N = True_Edges_Sym.shape[0]\n",
    "    mask = np.triu(np.ones((N, N), dtype=bool), k=1)\n",
    "    \n",
    "    # Flatten the matrices to compare only unique potential edges\n",
    "    True_Edges_Flat = True_Edges_Sym[mask]\n",
    "    Learned_Edges_Flat = Learned_Edges_Sym[mask]\n",
    "    \n",
    "    # True Positives (TP): Edges present in BOTH true and learned graphs\n",
    "    TP = np.sum(True_Edges_Flat * Learned_Edges_Flat)\n",
    "    \n",
    "    # False Positives (FP): Edges in Learned but NOT in True\n",
    "    FP = np.sum(Learned_Edges_Flat * (1 - True_Edges_Flat))\n",
    "    \n",
    "    # False Negatives (FN): Edges in True but NOT in Learned\n",
    "    FN = np.sum(True_Edges_Flat * (1 - Learned_Edges_Flat))\n",
    "    \n",
    "    # Total True Edges (P = Positives): TP + FN\n",
    "    num_edges_in_true = np.sum(True_Edges_Flat)\n",
    "    \n",
    "    # Total Learned Edges (P' = Predicted Positives): TP + FP\n",
    "    num_edges_in_learned = np.sum(Learned_Edges_Flat)\n",
    "    \n",
    "    # 4. Calculate Precision, Recall, and F1-Score\n",
    "\n",
    "    # Precision: TP / (TP + FP)\n",
    "    if num_edges_in_learned == 0:\n",
    "        precision = 1.0  # Convention: 1.0 if no edges are predicted\n",
    "    else:\n",
    "        precision = TP / num_edges_in_learned\n",
    "        \n",
    "    # Recall: TP / (TP + FN)\n",
    "    if num_edges_in_true == 0:\n",
    "        recall = 1.0  # Convention: 1.0 if the true graph has no edges\n",
    "    else:\n",
    "        recall = TP / num_edges_in_true\n",
    "\n",
    "    # F1-Score\n",
    "    if (precision + recall) == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(f\"|--- Structural Metrics (Edges Only) ---\")\n",
    "    print(f\"| Total True Edges (TP + FN): {num_edges_in_true}\")\n",
    "    print(f\"| Total Learned Edges (TP + FP): {num_edges_in_learned}\")\n",
    "    print(f\"| TP (Correctly Found Edges): {TP}\")\n",
    "    print(f\"| FP (Spurious Edges): {FP}\")\n",
    "    print(f\"| FN (Missed Edges): {FN}\")\n",
    "    print(f\"| Precision: {precision:.4f}\")\n",
    "    print(f\"| Recall:    {recall:.4f}\")\n",
    "    print(f\"| F1-Score:  {f1_score:.4f}\")\n",
    "    print(f\"|---------------------------------------\")\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "\n",
    "def run_pc_analysis_on_dataset(data_csv_path, truth_graph_npy_path, alpha=0.05, test_choice = 'fisherz'):\n",
    "    \"\"\"\n",
    "    runs complete PC analysis on a single dataset and compares it to the ground truth\n",
    "    \n",
    "    1. Load data and true graph\n",
    "    2. Run PC algorithm\n",
    "    3. Score the result using Structural Hamming Distance (SHD)\n",
    "    4. Plot the true graph vs. the learned graph.\n",
    "    \n",
    "    Args:\n",
    "        data_csv_path (str): Filepath to the simulation's _data.csv file.\n",
    "        truth_graph_npy_path (str): Filepath to the simulation's _graph.npy file.\n",
    "        alpha (float): Significance level for the PC algorithm's independence tests.\n",
    "                       A common value is 0.05.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the learned graph object and the SHD score.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Processing: {os.path.basename(data_csv_path)}\")\n",
    "    \n",
    "    # LOAD AND PREPARE DATA\n",
    "    df = pd.read_csv(data_csv_path)\n",
    "    if 'domain_index' in df.columns:\n",
    "        df = df.drop('domain_index', axis=1)\n",
    "    labels = df.columns.tolist()\n",
    "    data = df.to_numpy()\n",
    "    \n",
    "    # LOAD & CREATE GROUND TRUTH DAG OBJECT\n",
    "    # LOAD SAVED ADJACENCY MATRIX\n",
    "    true_adj_transposed = np.load(truth_graph_npy_path)\n",
    "    true_adj_matrix = true_adj_transposed.T\n",
    "    \n",
    "    # Create the Ground Truth Graph Object \n",
    "    # must convert NumPy matrix into GeneralGraph object\n",
    "    nodes = [GraphNode(name) for name in labels]\n",
    "    true_graph_obj = GeneralGraph(nodes)\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if true_adj_matrix[i, j] != 0:\n",
    "                true_graph_obj.add_directed_edge(nodes[i], nodes[j])\n",
    "    \n",
    "    # PC alg\n",
    "    print(\"Running PC alg\")\n",
    "    cg = pc(data, alpha=alpha, indep_test=test_choice)\n",
    "    \n",
    "    print(\"PC alg finished.\")\n",
    "    \n",
    "    # get learned graph object\n",
    "    learned_graph_obj = cg.G\n",
    "    \n",
    "    #check accuracy with SHD\n",
    "    #pass graph objects to SHD\n",
    "    # SHD receives true_graph_obj and learned_graph_obj\n",
    "    shd_score = SHD(true_graph_obj, learned_graph_obj).get_shd()\n",
    "    testing = SHD(true_graph_obj, learned_graph_obj)\n",
    "\n",
    "\n",
    "    calculate_and_print_metrics(true_graph_obj, learned_graph_obj)\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"\\n analysis done\")\n",
    "    print(f\"Structural Hamming Distance (SHD): {shd_score}\")\n",
    "    if shd_score == 0:\n",
    "        print(\"PC perfectly recovered the true causal graph\")\n",
    "    else:\n",
    "        print(f\"Learned graph is {shd_score} edge(s) different from the truth.\")\n",
    "    print(\"-------------------------\\n\")\n",
    "    \n",
    "    ### 5. VISUALIZE RESULTS ###\n",
    "    plot_title = os.path.basename(data_csv_path).replace('_data.csv', '')\n",
    "    \n",
    "    # Pass the two graph objects to the plotting function\n",
    "    plot_comparison_graphs(true_graph_obj, learned_graph_obj, labels, title_prefix=plot_title)\n",
    "    return {\n",
    "        'learned_graph_obj': learned_graph_obj,\n",
    "        'shd_score': shd_score,\n",
    "        'test': testing\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7897e3-d392-4711-b846-3984d0fc4a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pc in module causallearn.search.ConstraintBased.PC:\n",
      "\n",
      "pc(data: 'ndarray', alpha=0.05, indep_test='fisherz', stable: 'bool' = True, uc_rule: 'int' = 0, uc_priority: 'int' = 2, mvpc: 'bool' = False, correction_name: 'str' = 'MV_Crtn_Fisher_Z', background_knowledge: 'BackgroundKnowledge | None' = None, verbose: 'bool' = False, show_progress: 'bool' = True, node_names: 'List[str] | None' = None, **kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e84c0a-d3d4-42b8-954d-1d00fb315df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal-Learn: Version not accessible via standard attributes. Try 'pip show causal-learn'.\n"
     ]
    }
   ],
   "source": [
    "import causallearn\n",
    "try:\n",
    "    print(f\"Causal-Learn: {causallearn.__version__}\")\n",
    "except AttributeError:\n",
    "    # If __version__ fails, try importing the dedicated version submodule\n",
    "    try:\n",
    "        from causallearn import version\n",
    "        # Try version.__version__ (common pattern 2)\n",
    "        print(f\"Causal-Learn (via version submodule): {version.__version__}\")\n",
    "    except (ImportError, AttributeError):\n",
    "        # Final attempt: Try importing the __version__ from a known utility module\n",
    "        try:\n",
    "            from causallearn.utils.version import __version__ as cl_version\n",
    "            print(f\"Causal-Learn (via utils submodule): {cl_version}\")\n",
    "        except (ImportError, AttributeError):\n",
    "            print(\"Causal-Learn: Version not accessible via standard attributes. Try 'pip show causal-learn'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb35eb-974f-4bfe-9ca2-64c364f64ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5d66ae-cf67-4c07-920e-1bf23e9e272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: causal-learn in /opt/miniconda3/lib/python3.13/site-packages (0.1.4.3)\n",
      "Requirement already satisfied: pydot in /opt/miniconda3/lib/python3.13/site-packages (4.0.1)\n",
      "Requirement already satisfied: graphviz in /opt/miniconda3/lib/python3.13/site-packages (0.21)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (1.7.2)\n",
      "Requirement already satisfied: statsmodels in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (0.14.5)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (3.10.7)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (3.5)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (4.67.1)\n",
      "Requirement already satisfied: momentchi2 in /opt/miniconda3/lib/python3.13/site-packages (from causal-learn) (0.1.8)\n",
      "Requirement already satisfied: pyparsing>=3.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from pydot) (3.2.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->causal-learn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->causal-learn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->causal-learn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->causal-learn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->causal-learn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->causal-learn) (12.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/lib/python3.13/site-packages (from matplotlib->causal-learn) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->causal-learn) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.13/site-packages (from pandas->causal-learn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.13/site-packages (from pandas->causal-learn) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/miniconda3/lib/python3.13/site-packages (from scikit-learn->causal-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/miniconda3/lib/python3.13/site-packages (from scikit-learn->causal-learn) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /opt/miniconda3/lib/python3.13/site-packages (from statsmodels->causal-learn) (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install causal-learn pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edaa9f-6b25-4195-8e0c-ff6becc1d316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
